# This is a GitHub Actions workflow that automates uploading raw FRED API CSVs to Google Cloud Storage (GCS)
name: Upload Raw CSVs to GCS

# Trigger this workflow on the 1st of every month at 00:00 (midnight) UTC
on:
  schedule:
    - cron: '0 0 1 * *'  # (min hr dom mon dow) ‚Üí runs monthly on 1st at 00:00 UTC

  workflow_dispatch:  # Allows you to trigger this workflow manually from GitHub UI

jobs:
  upload-to-gcs:
    runs-on: ubuntu-latest  # Use the latest Ubuntu runner provided by GitHub

    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v3  # Clone your repo into the GitHub Actions runner

      - name: üêç Set up Python
        uses: actions/setup-python@v4  # Set up Python in the runner
        with:
          python-version: '3.10'  # Match your `.python-version` (3.10.13 will resolve to 3.10.x)

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip  # Make sure pip is up to date
          pip install google-cloud-storage  # Install GCS SDK to upload files programmatically

      - name: üîê Authenticate with GCP
        env:
          GCP_CREDENTIALS_JSON: ${{ secrets.GCP_CREDENTIALS_JSON }}  # Use GitHub Secret
        run: |
          echo "$GCP_CREDENTIALS_JSON" > key.json  # Dump the secret into a key file
          gcloud auth activate-service-account --key-file=key.json  # Authenticate with GCP
          gcloud config set project housing-bubble-predictor  # Set your GCP project

      - name: ‚òÅÔ∏è Upload raw CSVs to GCS
        run: |
          # Use gsutil to upload all raw .csv files recursively
          gsutil -m cp -r data/raw/*.csv gs://housing-bubble-predictor-data/Raw_Data_using_FRED_API/